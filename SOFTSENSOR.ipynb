{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5da84877-ee22-499d-ae3c-12231553ac5c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Import Widget packages\n",
    "import ipyvuetify as v\n",
    "import pandas as pd\n",
    "import ipywidgets\n",
    "from seeq import sdk\n",
    "import urllib.parse as urlparse\n",
    "from urllib.parse import parse_qs\n",
    "import re\n",
    "import sys\n",
    "import uuid\n",
    "import pytz\n",
    "import datetime\n",
    "from datetime import date\n",
    "import pickle\n",
    "import io\n",
    "from ipyvuetify.extra import FileInput\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f64483a-8414-4f11-b87d-5a0fd512cf42",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Import Sklearn packages\n",
    "import numpy as np\n",
    "import math\n",
    "import smogn\n",
    "import imblearn\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import make_scorer, mean_absolute_percentage_error, accuracy_score, mean_absolute_error\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.base import is_classifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.base import TransformerMixin, BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af0cc8c4-fcbb-41dc-9f2a-7d326abb2612",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "miss_threshold = 20 # Max percentage of missing data allowed before dropping a feature\n",
    "imbalance_threshold = 0.2 # Max imbalance ratio to consider imbalanced data for classifiation\n",
    "global loaded_object \n",
    "loaded_object = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b74fdaba-5ac1-4743-be49-dff4756ccff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widgets\n",
    "app = v.App()\n",
    "\n",
    "image = v.Img(\n",
    "    lazy_src=\"https://seeq.com/sites/default/files/seeq-content/seeq-logo-blue-web-33h.svg\",\n",
    "    aspect_ratio=\"16/9\",\n",
    "    width=100,\n",
    "    src=\"https://seeq.com/sites/default/files/seeq-content/seeq-logo-blue-web-33h.svg\",\n",
    ")\n",
    "message = v.Text(\n",
    "    children=[\"Soft Sensor Add-On\"],\n",
    "    style_=\"font-size:22px\"\n",
    ")\n",
    "\n",
    "message2 = v.Text(\n",
    "    children=[\"A simple tool to predict a signal based on multiple regressor signals with Machine Learning models\"],\n",
    "    style_=\"font-size:15px\"\n",
    ")\n",
    "\n",
    "# Create a layout with space between the widgets\n",
    "layout = v.Layout(\n",
    "    row=True,\n",
    "    children=[\n",
    "        message,\n",
    "        v.Spacer(),  # This will introduce space between the widgets\n",
    "        message2\n",
    "    ]\n",
    ")\n",
    "\n",
    "header = v.Container(children=[image,layout])\n",
    "\n",
    "url_input = v.TextField(label='Workbench URL', v_model=None)\n",
    "\n",
    "execute_button = v.Btn(\n",
    "    button_style='success',\n",
    "    children=['Get Signals']\n",
    ")\n",
    "\n",
    "\n",
    "items_dropdown = v.Select(item_text='Name', \n",
    "                          item_value='ID', \n",
    "                          label=\"Select signal to predict\", \n",
    "                          v_model=None, \n",
    "                          return_object=True,\n",
    "                          disabled = True\n",
    "                         )\n",
    "\n",
    "regressors = v.Select(item_text='Name', \n",
    "                      item_value='ID', \n",
    "                      label=\"Select regressors\", \n",
    "                      v_model=None, \n",
    "                      return_object=True,\n",
    "                      multiple=True,\n",
    "                      disabled=True\n",
    "                    )\n",
    "\n",
    "# File input widget\n",
    "file_input = FileInput(\n",
    "    accept='.pkl',  # Accept all file types\n",
    "    multiple=False,  # Allow only single file selection\n",
    "    label='Upload pre-trained model (.pkl)',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Vertical divider\n",
    "divider = v.Divider(vertical=True)\n",
    "\n",
    "# Create a horizontal layout to arrange the widgets\n",
    "layout_regressors_file = v.Row(children=[\n",
    "    v.Col(children=[regressors]),\n",
    "    v.Col(children=[divider]),\n",
    "    v.Col(children=[file_input])\n",
    "])\n",
    "\n",
    "start_select = v.DatePicker(label='Prediction Start:', v_model=None, first_day_of_week = 1, no_title = False, max=date.today().isoformat(),disabled=True)\n",
    "end_select = v.DatePicker(label='Prediction End:', v_model=None, first_day_of_week = 1, no_title = False, max=date.today().isoformat(),disabled=True)\n",
    "\n",
    "start_select_1 = v.DatePicker(label='Prediction Start:', v_model=None, first_day_of_week = 1, no_title = False, max=date.today().isoformat(),disabled=True)\n",
    "end_select_1 = v.DatePicker(label='Prediction End:', v_model=None, first_day_of_week = 1, no_title = False, max=date.today().isoformat(),disabled=True)\n",
    "\n",
    "\n",
    "# Create a layout with labels and minimal spacing, and grey out the labels\n",
    "layout = v.Row(\n",
    "    class_='d-flex align-center',\n",
    "    children=[\n",
    "        v.Col(\n",
    "            children=[\n",
    "                v.Html(tag='label', children=['Prediction window start:'], class_='mr-1', style_='color: grey;'),  # Grey out the label\n",
    "                start_select_1\n",
    "            ],\n",
    "            cols=5,\n",
    "            class_='pr-1'  # Reduced padding\n",
    "        ),\n",
    "        v.Col(\n",
    "            children=[\n",
    "                v.Html(tag='label', children=['Prediction window end:'], class_='mr-1', style_='color: grey;'),  # Grey out the label\n",
    "                end_select_1\n",
    "            ],\n",
    "            cols=5,\n",
    "            class_='pl-1'  # Reduced padding\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "layout3 = v.Row(\n",
    "    class_='d-flex align-center',\n",
    "    children=[\n",
    "        v.Col(\n",
    "            children=[\n",
    "                v.Html(tag='label', children=['Training window start:    '], class_='mr-1', style_='color: grey;'),  # Grey out the label\n",
    "                start_select\n",
    "            ],\n",
    "            cols=5,\n",
    "            class_='pr-1'  # Reduced padding\n",
    "        ),\n",
    "        v.Col(\n",
    "            children=[\n",
    "                v.Html(tag='label', children=['Training window end:    '], class_='mr-1', style_='color: grey;'),  # Grey out the label\n",
    "                end_select\n",
    "            ],\n",
    "            cols=5,\n",
    "            class_='pl-1'  # Reduced padding\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "layout_dates = v.Row(children=[\n",
    "    v.Col(children=[layout3]),\n",
    "    v.Col(children=[layout])\n",
    "])\n",
    "\n",
    "# Add vertical space below the layout\n",
    "vertical_space = v.Html(tag='div', class_='mb-4')  # Add margin-bottom for vertical space\n",
    "\n",
    "submit_button = v.Btn(\n",
    "    button_style='success',\n",
    "    children=['Submit'])\n",
    "submit_button.disabled = True\n",
    "\n",
    "warning_error_message = v.Text(\n",
    "    children=[\"\"],\n",
    "    style_=\"font-size:15px\"\n",
    ")\n",
    "\n",
    "info_message = v.Textarea(\n",
    "    value=\"\",\n",
    "    style_=\"font-size:15px\",\n",
    "    auto_grow=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "input_container = v.Container(children=[url_input,\n",
    "                                        execute_button,\n",
    "                                        items_dropdown,\n",
    "                                        layout_regressors_file,\n",
    "                                        #layout3,\n",
    "                                        #layout,\n",
    "                                        layout_dates,\n",
    "                                        vertical_space,\n",
    "                                        submit_button,\n",
    "                                        vertical_space,\n",
    "                                        warning_error_message,\n",
    "                                        vertical_space,\n",
    "                                        info_message])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db26cedc-3bff-4d95-81bc-7d77f8f68b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get signals button\n",
    "def get_worksheet_items(*args):\n",
    "    \n",
    "    execute_button.loading = True\n",
    "\n",
    "    # Get Items on worksheet and populate signal dropdown and regressor multiselect\n",
    "    if is_valid_seeq_url(url_input.v_model) == False:\n",
    "        warning_error_message.children = [\"Invalid Workbench URL\"]\n",
    "        warning_error_message.style_ = \"font-size:15px; color: Black; background-color: red;\"\n",
    "        execute_button.loading = False\n",
    "        start_select.disabled = True\n",
    "        end_select.disabled = True\n",
    "        start_select_1.disabled = True\n",
    "        end_select_1.disabled = True\n",
    "        layout.children[0].children[0].style_ = 'color: grey;'  # First label\n",
    "        layout.children[1].children[0].style_ = 'color: grey;'  # Second label\n",
    "        layout3.children[0].children[0].style_ = 'color: grey;'  # First label\n",
    "        layout3.children[1].children[0].style_ = 'color: grey;'  # Second label\n",
    "        exit\n",
    "        \n",
    "    else:\n",
    "        warning_error_message.children = [\"\"]\n",
    "        warning_error_message.style_ = \"font-size:15px; color: Black; background-color: white;\"\n",
    "        \n",
    "        items = spy.search(url_input.v_model, quiet=True)\n",
    "        signals = items.loc[items.Type.str.contains('Signal')]\n",
    "        dropdown_items = list(signals[['Name','ID']].T.to_dict().values())\n",
    "        items_dropdown.items = dropdown_items\n",
    "        items_dropdown.select = dropdown_items[0]\n",
    "        items_dropdown.disabled=False\n",
    "        regressors.items = dropdown_items\n",
    "        regressors.disabled=False\n",
    "        submit_button.disabled=False\n",
    "        \n",
    "        # Color labels to indicate active widgets\n",
    "        execute_button.loading = False\n",
    "        start_select.disabled = False\n",
    "        end_select.disabled = False\n",
    "        start_select_1.disabled = False\n",
    "        end_select_1.disabled = False\n",
    "        layout.children[0].children[0].style_ = 'color: black;'  # First label\n",
    "        layout.children[1].children[0].style_ = 'color: black;'  # Second label\n",
    "        layout3.children[0].children[0].style_ = 'color: black;'  # First label\n",
    "        layout3.children[1].children[0].style_ = 'color: black;'  # Second label\n",
    "\n",
    "        \n",
    "        # Fetch worksheet date range\n",
    "        wb = spy.workbooks.pull(url_input.v_model)\n",
    "        \n",
    "        # Regular expression to extract the worksheet ID\n",
    "        pattern = r\"/worksheet/([a-zA-Z0-9-]+)\"\n",
    "        \n",
    "        # Search for the pattern in the URL\n",
    "        match = re.search(pattern, url_input.v_model)\n",
    "        \n",
    "        # Find the current worksheet based on the worksheetId in the query parameters\n",
    "        current_worksheet = [ws for ws in wb[0].worksheets if ws.id ==match.group(1)][0]\n",
    "        \n",
    "        # Get Display Range\n",
    "        display_range = current_worksheet.display_range\n",
    "        \n",
    "        # Insert values into ipydatetime widget\n",
    "        layout.children[0].children[1].v_model = display_range['Start'].date().isoformat()\n",
    "        layout.children[1].children[1].v_model = display_range['End'].date().isoformat()\n",
    "        layout3.children[0].children[1].v_model = display_range['Start'].date().isoformat()\n",
    "        layout3.children[1].children[1].v_model = display_range['End'].date().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73dd486b-6c39-42d0-97f3-979678ed3bb0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Update regressors when choosing signal to predict\n",
    "def update_regressors(change):\n",
    "    selected_item = items_dropdown.v_model\n",
    "    # Filter out the selected item from regressors\n",
    "    \n",
    "    regressors.items = [item for item in items_dropdown.items if item['Name'] != selected_item['Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c189c9b-1b99-4c1c-afeb-76006cf97c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "def combine_to_list(item1, item2):\n",
    "    # Check if both items are strings\n",
    "    if isinstance(item1, str) and isinstance(item2, str):\n",
    "        return [item1, item2]\n",
    "    \n",
    "    # Check if one item is a string and the other is a list\n",
    "    elif isinstance(item1, str) and isinstance(item2, list):\n",
    "        return [item1] + item2\n",
    "    elif isinstance(item1, list) and isinstance(item2, str):\n",
    "        return item1 + [item2]\n",
    "\n",
    "# Define the custom scoring function (inverse of MAPE)\n",
    "def custom_mape_scorer(y_true, y_pred):\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    return 1 - mape\n",
    "\n",
    "# Define the custom scoring function (inverse of MAE)\n",
    "def custom_mae_scorer(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    return 1 / mae\n",
    "\n",
    "# Function to check if the URL is a valid Seeq address\n",
    "def is_valid_seeq_url(url):\n",
    "    try:\n",
    "        \n",
    "        # Attempt to perform a search using the URL\n",
    "        spy.search(url, quiet=True)\n",
    "        \n",
    "        # If no exception is raised, the URL is considered valid\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        # If an exception is raised, the URL is considered invalid\n",
    "        return False\n",
    "\n",
    "def get_signal_unit(signal_id):\n",
    "    \"\"\"Retrieves the unit of a Seeq signal given its ID.\"\"\"\n",
    "    try:\n",
    "        signals = spy.search({'ID': signal_id, 'Type': 'Signal'}, quiet=True)\n",
    "        if not signals.empty:  # Check if any signals were found\n",
    "            return signals['Units'].iloc[0] # Access units from the dataframe returned by spy.search\n",
    "        else:\n",
    "            print(f\"Signal with ID '{signal_id}' not found.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while retrieving signal metadata: {e}\")\n",
    "        return None\n",
    "\n",
    "        \n",
    "# Create a new event handler for file_input successful load\n",
    "def on_file_upload(change):\n",
    "    global loaded_object\n",
    "    loaded_object = None\n",
    "    \n",
    "    try:\n",
    "        file = file_input.get_files()[0]\n",
    "        if not file: # if the list is empty, trigger an index error.\n",
    "          raise IndexError(\"No files uploaded.\")\n",
    "        else:\n",
    "            file_content = file['file_obj']\n",
    "            byte_data = file_content.read()\n",
    "            loaded_object = pickle.loads(byte_data)\n",
    "            start_select.disabled = True\n",
    "            end_select.disabled = True \n",
    "    except IndexError as e:\n",
    "        start_select.disabled = False\n",
    "        end_select.disabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65325e82-a981-43fe-8c4e-4ece6739805d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Classifier model parameters and hyperparameters for GridSearchCV\n",
    "classifier_models = {\n",
    "    'knn': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'model__n_neighbors': [3, 5, 7, 9],\n",
    "            'model__weights': ['uniform', 'distance'],\n",
    "            'model__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': [\n",
    "            {\n",
    "                'model__C': [0.1, 1, 10],\n",
    "                'model__penalty': ['l1', 'l2'],\n",
    "                'model__solver': ['liblinear'],\n",
    "                'model__class_weight': ['balanced', None] \n",
    "            },\n",
    "            {\n",
    "                'model__C': [0.1, 1, 10],\n",
    "                'model__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                'model__solver': ['saga'],\n",
    "                'model__l1_ratio': [0.15, 0.5, 0.85],\n",
    "                'model__class_weight': ['balanced', None] \n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    'random_forest': {\n",
    "    'model': RandomForestClassifier(),\n",
    "    'params': {\n",
    "        'model__n_estimators': [50, 100, 200, 300],\n",
    "        'model__max_depth': [None, 10, 20, 30],\n",
    "        'model__max_features': [0.5, 0.6, 0.7, 0.8],\n",
    "        'model__max_leaf_nodes': [6, 7, 8, 9, 10],\n",
    "        'model__class_weight': ['balanced', 'balanced_subsample', None] \n",
    "        }\n",
    "    },\n",
    "    'gradient_boosting_classifier': {\n",
    "        'model': GradientBoostingClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [50, 100, 200],\n",
    "            'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "            'model__max_depth': [3, 5, 7],\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3ca304d-297b-4287-8f7c-460aee0bb731",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Regression model parameters and hyperparameters for GridSearchCV\n",
    "regression_models = {\n",
    "\t\t'knn' : {\n",
    "\t\t    'model': KNeighborsRegressor(),\n",
    "\t\t    'params': {\n",
    "\t\t        'model__n_neighbors': [3, 5, 7, 9],\n",
    "\t\t        'model__weights': ['uniform', 'distance'],\n",
    "\t\t        'model__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "\t\t    }\n",
    "\t\t},\n",
    "    'ridge_regression': {\n",
    "        'model': Ridge(),\n",
    "        'params': {\n",
    "            'model__alpha': [0.1, 1, 10, 50]\n",
    "        }\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [50, 100, 200,300],\n",
    "            'model__max_depth': [None, 10, 20, 30],\n",
    "            'model__max_features': [0.5, 0.6, 0.7, 0.8],\n",
    "            'model__max_leaf_nodes':[6, 7, 8, 9, 10]\n",
    "        }\n",
    "    },\n",
    "    'gradient_boosting': {\n",
    "        'model': GradientBoostingRegressor(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [50, 100, 200],\n",
    "            'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "            'model__max_depth': [3, 5, 7]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02d22795-e248-4ca0-80f7-73c3297093a4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Submit button\n",
    "def submit_formula(*args):\n",
    "\n",
    "    # Clear warning messages\n",
    "    warning_error_message.children = [\"\"]\n",
    "    warning_error_message.style_ = \"font-size:15px; color: Black; background-color: white;\"\n",
    "    \n",
    "    # Get the workbook and worksheet IDs from the URL\n",
    "    submit_button.loading = True\n",
    "    info_message.value = \"Pulling data...\"\n",
    "    info_message.style_ = \"font-size:15px; color: Black; background-color: white;\"\n",
    "\n",
    "    # Get the workbook and worksheet IDs from the URL\n",
    "    url  = url_input.v_model\n",
    "    workbook_id = spy.utils.get_workbook_id_from_url(url)\n",
    "    worksheet_id = spy.utils.get_worksheet_id_from_url(url)\n",
    "    timezone = spy.pull(url).index.tz\n",
    "    \n",
    "    # Get start and end date\n",
    "    start_date = pd.to_datetime(layout3.children[0].children[1].v_model).tz_localize(timezone)\n",
    "    end_date = pd.to_datetime(layout3.children[1].children[1].v_model).tz_localize(timezone)\n",
    "    \n",
    "    start_date_preds = pd.to_datetime(layout.children[0].children[1].v_model).tz_localize(timezone)\n",
    "    end_date_preds = pd.to_datetime(layout.children[1].children[1].v_model).tz_localize(timezone)\n",
    "\n",
    "    # Warning messages\n",
    "    if end_date <= start_date and not loaded_object:\n",
    "        warning_error_message.children = [\"Invalid date ranges for training window\"]\n",
    "        warning_error_message.style_ = \"font-size:15px; color: Black; background-color: red;\"\n",
    "        info_message.value = \"\"\n",
    "        info_message.style_ = \"font-size:15px; color: Black; background-color: white;\"\n",
    "        submit_button.loading=False\n",
    "    elif end_date_preds <= start_date_preds:\n",
    "        warning_error_message.children = [\"Invalid date ranges for prediction window\"]\n",
    "        warning_error_message.style_ = \"font-size:15px; color: Black; background-color: red;\"\n",
    "        info_message.value = \"\"\n",
    "        info_message.style_ = \"font-size:15px; color: Black; background-color: white;\"\n",
    "        submit_button.loading=False\n",
    "\n",
    "    if items_dropdown.v_model == None and regressors.v_model == None:\n",
    "        warning_error_message.children = [\"No prediction nor regressor signals selected\"]\n",
    "        warning_error_message.style_ = \"font-size:15px; color: Black; background-color: red;\"\n",
    "        info_message.value = \"\"\n",
    "        info_message.style_ = \"font-size:15px; color: Black; background-color: white;\"\n",
    "        submit_button.loading=False\n",
    "    elif items_dropdown.v_model == None:\n",
    "        warning_error_message.children = [\"No prediction signal selected\"]\n",
    "        warning_error_message.style_ = \"font-size:15px; color: Black; background-color: red;\"\n",
    "        info_message.value = \"\"\n",
    "        info_message.style_ = \"font-size:15px; color: Black; background-color: white;\"\n",
    "        submit_button.loading=False\n",
    "    elif regressors.v_model == None:\n",
    "        warning_error_message.children = [\"No regressor signals selected\"]\n",
    "        warning_error_message.style_ = \"font-size:15px; color: Black; background-color: red;\"\n",
    "        info_message.value = \"\"\n",
    "        info_message.style_ = \"font-size:15px; color: Black; background-color: white;\"\n",
    "        submit_button.loading=False\n",
    "\n",
    "    # Search for the worksheet\n",
    "    ws = spy.search({'ID': worksheet_id}, quiet=True)\n",
    "    worksheet_name = ws['Name'].iloc[0]\n",
    "    \n",
    "    # Search for the signals given IDs\n",
    "    signal_IDs = combine_to_list(items_dropdown.v_model['ID'],[item['ID'] for item in regressors.v_model])\n",
    "    unit = spy.search({'ID': items_dropdown.v_model['ID'], 'Type': 'Signal'}, quiet=True).get('Value Unit Of Measure').iloc[0]\n",
    "    \n",
    "    all_signals = pd.DataFrame()\n",
    "    for signal_id in signal_IDs:\n",
    "        signals = spy.search({'ID': signal_id, 'Type': 'Signal'}, quiet=True)\n",
    "        all_signals = pd.concat([all_signals, signals], ignore_index=True)\n",
    "\n",
    "    # Pull the data for the signals within the specified date range\n",
    "    try:\n",
    "        all_signals_df_preds = spy.pull(all_signals, start=start_date_preds, end=end_date_preds,header='ID', grid = None)\n",
    "        if loaded_object is not None:\n",
    "           all_signals_df = all_signals_df_preds.copy()\n",
    "        else:\n",
    "            all_signals_df = spy.pull(all_signals, start=start_date, end=end_date,header='ID',grid = None)\n",
    "        \n",
    "    except Exception as e:\n",
    "        warning_error_message.children = [f\"Something went wrong when pulling Seeq data: {e}\"]\n",
    "        warning_error_message.style_ = \"font-size:15px; color: Black; background-color: red;\"\n",
    "        info_message.value = \"\"\n",
    "        info_message.style_ = \"font-size:15px; color: Black; background-color: white;\"\n",
    "        submit_button.loading=False\n",
    "\n",
    "    \n",
    "    # Determine whether we are dealing with a regression or classification problem\n",
    "    variable_signal_to_predict = all_signals_df[items_dropdown.v_model['ID']].dtype\n",
    "    \n",
    "    if pd.api.types.is_numeric_dtype(variable_signal_to_predict):\n",
    "        # Select regression models\n",
    "        models = regression_models\n",
    "        class_imbalance = False\n",
    "        \n",
    "        # Assign most representative metric depending on values of variable to predict\n",
    "        if all_signals_df[items_dropdown.v_model['ID']].apply(lambda x: abs(x) < 0.1).all():\n",
    "            scoring_metric = make_scorer(custom_mae_scorer, greater_is_better=True)\n",
    "            metric_name = \"1/MAE\"\n",
    "        else:\n",
    "            scoring_metric = make_scorer(custom_mape_scorer, greater_is_better=True)\n",
    "            metric_name = \"1-MAPE\"\n",
    "        \n",
    "    else:\n",
    "        # Select classification models\n",
    "        models = classifier_models\n",
    "\n",
    "        # Detect class imbalance\n",
    "        class_counts = all_signals_df[items_dropdown.v_model['ID']].value_counts()\n",
    "        imbalance_ratio = class_counts.min() / class_counts.max()\n",
    "        if imbalance_ratio <= imbalance_threshold:\n",
    "            class_imbalance = True\n",
    "        else: \n",
    "            class_imbalance = False\n",
    "\n",
    "        # Assign most representative metric depending on binary or multiclass variable to predict\n",
    "        scoring_metric = \"balanced_accuracy\"\n",
    "        metric_name = \"Balanced accuracy\"\n",
    "        \n",
    "    # Reset the index to ensure proper alignment of data points\n",
    "    all_signals_df.reset_index(inplace=True)\n",
    "    \n",
    "    info_message.value = \"Preprocessing data...\"\n",
    "    info_message.style_ = \"font-size:15px; color: Black; background-color: white;\"\n",
    "\n",
    "    # Eliminate regressors where too many values are missing\n",
    "    missing_percentage = all_signals_df.iloc[:, 2:].isna().mean() * 100\n",
    "    columns_to_drop = missing_percentage[missing_percentage >= miss_threshold].index\n",
    "    all_signals_df.drop(columns=columns_to_drop, inplace=True)\n",
    "    all_signals_df_preds.drop(columns=columns_to_drop, inplace=True)\n",
    "    \n",
    "    # Create df copy for predictions\n",
    "    df_to_predict = all_signals_df_preds.copy()\n",
    "\n",
    "    # Clean missing values for target variable and drop date column\n",
    "    all_signals_df = all_signals_df.drop(all_signals_df.columns[0], axis=1)\n",
    "    all_signals_df = all_signals_df.dropna(subset=[all_signals_df.columns[0]])\n",
    "    \n",
    "    #Additional warnings\n",
    "    if all_signals_df.shape[1] == 2:\n",
    "        warning_error_message.children = [\"Only one valid regressor for predictions\"]\n",
    "        warning_error_message.style_ = \"font-size:15px; color: Black; background-color: yellow;\"\n",
    "    elif all_signals_df.shape[1] == 1:\n",
    "        warning_error_message.children = [\"No valid regressors for predictions\"]\n",
    "        warning_error_message.style_ = \"font-size:15px; color: Black; background-color: red;\"\n",
    "        info_message.value = \"\"\n",
    "        info_message.style_ = \"font-size:15px; color: Black; background-color: white;\"\n",
    "        submit_button.loading=False\n",
    "        exit\n",
    "\n",
    "    # Identify numerical, categorical columns, variable to predict and regressors\n",
    "    X = all_signals_df.drop(columns=all_signals_df.columns[0])\n",
    "    y = all_signals_df[all_signals_df.columns[0]]\n",
    "    X_valid = df_to_predict.iloc[:, 1:]\n",
    "    numerical_cols = all_signals_df.drop(columns=all_signals_df.columns[0]).select_dtypes(include=['int64', 'float64','float32']).columns.tolist()\n",
    "    categorical_cols = all_signals_df.drop(columns=all_signals_df.columns[0]).select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Preprocessing for numerical data\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', IterativeImputer()),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    # Preprocessing for categorical data\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore',sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    # Bundle preprocessing for numerical and categorical data\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ])\n",
    "    \n",
    "    string = \"\"\n",
    "    max_width = 0\n",
    "    \n",
    "    # Find the maximum width for the model names and parameters\n",
    "    max_name_width = max(len(name) for name in models.keys())\n",
    "    max_params_width = max(len(str(model['params'])) for model in models.values())\n",
    "    \n",
    "    best_score = float('-inf')\n",
    "\n",
    "\n",
    "    # Perform GridSearchCV for each model\n",
    "    if loaded_object is None:\n",
    "        for model_name, model_info in models.items():\n",
    "        \n",
    "            message = string + f\"Testing {model_name}: {model_info['params']}...\"\n",
    "            info_message.value = message\n",
    "            info_message.style_ = \"font-size:15px; color: Black; background-color: white;\"\n",
    "        \n",
    "            # Create a pipeline with preprocessors and the model\n",
    "            steps = [('preprocessor', preprocessor)]\n",
    "        \n",
    "            # Add SMOTE if necessary\n",
    "            if class_imbalance == True and models == classifier_models:\n",
    "                steps.append(('SMOTE', SMOTE(sampling_strategy='auto')))\n",
    "        \n",
    "            # Add model and convert into imbpipeline to avoid data leakage\n",
    "            steps.append(('pca', PCA(n_components=0.95)))\n",
    "            steps.append(('model', model_info['model']))\n",
    "            pipeline = imbpipeline(steps)\n",
    "        \n",
    "            # GridSearch\n",
    "            grid_search = GridSearchCV(pipeline, model_info['params'], cv=5, n_jobs=-1, scoring=scoring_metric, error_score='raise')\n",
    "            try:\n",
    "                grid_search.fit(X, y)\n",
    "            except Exception as e:\n",
    "                warning_error_message.children = [f\"Something went wrong during fitting: : {e}\"]\n",
    "                warning_error_message.style_ = \"font-size:15px; color: Black; background-color: red;\"\n",
    "                info_message.value = \"\"\n",
    "                info_message.style_ = \"font-size:15px; color: Black; background-color: white;\"\n",
    "                submit_button.loading=False\n",
    "            \n",
    "            string = string + f\"{model_name:<{max_name_width}}....Best {metric_name}: {grid_search.best_score_:.3f}....Best params: {str(grid_search.best_params_)}\\n\"\n",
    "            if grid_search.best_score_ > best_score:\n",
    "                best_score = grid_search.best_score_\n",
    "                best_model = grid_search.best_estimator_\n",
    "                \n",
    "        message = string + f\"Generating predictions with {best_model[-1]}...\\n\"\n",
    "        info_message.value = message\n",
    "        preds = best_model.predict(X_valid)\n",
    "\n",
    "    else:\n",
    "        message = string + f\"Generating predictions with loaded model {loaded_object}...\\n\"\n",
    "        try:\n",
    "            preds = loaded_object.predict(X_valid)\n",
    "        except Exception as e:\n",
    "            warning_error_message.children = [f\"Something went wrong during prediction: : {e}\"]\n",
    "            warning_error_message.style_ = \"font-size:15px; color: Black; background-color: red;\"\n",
    "            info_message.value = \"\"\n",
    "            info_message.style_ = \"font-size:15px; color: Black; background-color: white;\"\n",
    "            submit_button.loading=False\n",
    "    \n",
    "    # Generate signal name\n",
    "    new_signal_name = \"Soft_\" + items_dropdown.v_model['Name']\n",
    "    \n",
    "    # Predict with timestamp\n",
    "    preds = pd.DataFrame(preds, columns=[new_signal_name])\n",
    "    preds.index = X_valid.index\n",
    "\n",
    "    # Encode classification labels to be able to push directly to Seeq\n",
    "    if not pd.api.types.is_numeric_dtype(preds.iloc[:, 0]):\n",
    "        label_encoder = LabelEncoder()\n",
    "        preds.iloc[:, 0] = label_encoder.fit_transform(preds.iloc[:, 0])\n",
    "        mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "        if loaded_object is None:\n",
    "            desc = f\"Soft sensor predicted with {best_model[-1]} and regressors: {[item['Name'] for item in regressors.v_model]}. {metric_name}: {grid_search.best_score_:.3f}. Mapping: {mapping}\"\n",
    "        else:\n",
    "            desc = f\"Soft sensor predicted with loaded model {loaded_object} and regressors: {[item['Name'] for item in regressors.v_model]}. Mapping: {mapping}\"\n",
    "    else:\n",
    "        if loaded_object is None:\n",
    "            desc = f\"Soft sensor predicted with {best_model[-1]} and regressors: {[item['Name'] for item in regressors.v_model]}. {metric_name}: {grid_search.best_score_:.3f}\"\n",
    "        else:\n",
    "            desc = f\"Soft sensor predicted with loaded model {loaded_object} and regressors: {[item['Name'] for item in regressors.v_model]}.\"\n",
    "\n",
    "    # Metadata including Units\n",
    "    metadata = pd.DataFrame({\n",
    "        'Name': [new_signal_name],  # Required\n",
    "        'Description':  [desc],\n",
    "        'Units': [unit],\n",
    "        'Type': [\"Signal\"]\n",
    "    })\n",
    "    metadata.index = [new_signal_name]\n",
    "\n",
    "    # Push the data to Seeq\n",
    "    try:\n",
    "        spy.push(data=preds, \n",
    "         workbook=workbook_id, \n",
    "         worksheet=worksheet_id,\n",
    "         metadata = metadata,\n",
    "         quiet=True)\n",
    "        message = message + f\"Data for signal {new_signal_name} succesfully pushed.\"\n",
    "        info_message.value = message\n",
    "        info_message.style_ = \"font-size:15px; color: Black; background-color: #90EE90;\"\n",
    "        warning_error_message.children = [\"\"]\n",
    "        warning_error_message.style_ = \"font-size:15px; color: Black; background-color: white;\"\n",
    "        submit_button.loading=False\n",
    "    except Exception as e:\n",
    "        warning_error_message.children = [f\"Something went wrong when pushing back to Seeq Workbench: {e}\"]\n",
    "        warning_error_message.style_ = \"font-size:15px; color: Black; background-color: red;\"\n",
    "        info_message.value = \"\"\n",
    "        info_message.style_ = \"font-size:15px; color: Black; background-color: white;\"\n",
    "        submit_button.loading=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3198219-0370-4211-88e5-02bcbb31afc9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Event handling\n",
    "execute_button.on_event('click',get_worksheet_items)\n",
    "items_dropdown.observe(update_regressors, names='v_model')\n",
    "submit_button.on_event('click', submit_formula)\n",
    "file_input.observe(on_file_upload, names='file_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4a5442b-2f46-4370-97cb-828229ad55df",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2550f47442449998267ebe7c4639174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "App(children=[Container(children=[Img(aspect_ratio='16/9', layout=None, lazy_src='https://seeq.com/sites/defau…"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output \n",
    "app.children=[\n",
    "        header,\n",
    "        input_container\n",
    "    ]\n",
    "app"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
